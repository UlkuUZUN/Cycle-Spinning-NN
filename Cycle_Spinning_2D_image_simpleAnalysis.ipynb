{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM37iK2x6Ba32e4A6Fo3GvZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import sys\n","\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","import keras \n","from numpy.lib.stride_tricks import as_strided\n","from sklearn.preprocessing import normalize\n","\n","\n","# Grayscale Image\n","def processImage(image):\n","    image = cv2.imread(image)\n","    image = cv2.cvtColor(src=image, code=cv2.COLOR_BGR2GRAY)\n","    return image\n","\n","\n","def convolve2D(image, kernel, padding=0, strides=1):\n","    # Cross Correlation\n","    kernel = np.flipud(np.fliplr(kernel))\n","\n","    # Gather Shapes of Kernel + Image + Padding\n","    xKernShape = kernel.shape[0]\n","    yKernShape = kernel.shape[1]\n","    xImgShape = image.shape[0]\n","    yImgShape = image.shape[0]\n","\n","    # Shape of Output Convolution\n","    xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1)\n","    yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1)\n","    output = np.zeros((xOutput, yOutput))\n","\n","    # Apply Equal Padding to All Sides\n","    if padding != 0:\n","        imagePadded = np.zeros((image.shape[0] + padding*2, image.shape[1] + padding*2))\n","        imagePadded[int(padding):int(-1 * padding), int(padding):int(-1 * padding)] = image\n","    else:\n","        imagePadded = image\n","\n","    # Iterate through image\n","    for y in range(image.shape[1]):\n","        # Exit Convolution\n","        if y > image.shape[1] - yKernShape:\n","            break\n","        # Only Convolve if y has gone down by the specified Strides\n","        if y % strides == 0:\n","            for x in range(image.shape[0]):\n","                # Go to next row once kernel is out of bounds\n","                if x > image.shape[0] - xKernShape:\n","                    break\n","                try:\n","                    # Only Convolve if x has moved by the specified Strides\n","                    if x % strides == 0:\n","                        output[x, y] = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]).sum()\n","                except:\n","                    break\n","\n","    return output\n","\n","def relu(feature_map):  \n","    #Preparing the output of the ReLU activation function.  \n","     relu_out = np.zeros(feature_map.shape)  \n","     print(feature_map.shape[1])\n","     for map_num in range(feature_map.shape[-1]):  \n","          for r in np.arange(0,feature_map.shape[0]):  \n","              for c in np.arange(0, feature_map.shape[1]):  \n","                  relu_out[r, c] = np.max(feature_map[r, c], 0) \n","     return relu_out\n","def pool2d(A, kernel_size, stride, padding=0, pool_mode='max'):\n","    '''\n","    2D Pooling\n","\n","    Parameters:\n","      A: input 2D array\n","      kernel_size: int, the size of the window over which we take pool\n","      stride: int, the stride of the window\n","      padding: int, implicit zero paddings on both sides of the input\n","      pool_mode: string, 'max' or 'avg'\n","    '''\n","    # Padding\n","    A = np.pad(A, padding, mode='constant')\n","\n","    # Window view of A\n","    output_shape = ((A.shape[0] - kernel_size) // stride + 1,\n","                (A.shape[1] - kernel_size) // stride + 1)\n","\n","    shape_w = (output_shape[0], output_shape[1], kernel_size, kernel_size)\n","    strides_w = (stride*A.strides[0], stride*A.strides[1], A.strides[0], A.strides[1])\n","\n","    A_w = as_strided(A, shape_w, strides_w)\n","\n","    # Return the result of pooling\n","    if pool_mode == 'max':\n","      return A_w.max(axis=(2, 3))\n","    elif pool_mode == 'avg':\n","      return A_w.mean(axis=(2, 3))\n","\n","if __name__ == '__main__':\n","    # Grayscale Image   \n","    image = processImage('Picture2.png') \n","    #XDirection Kernel\n","    kernel=np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n"," \n","\n","    # Convolve and Save Output\n","    output = convolve2D(image, kernel, padding=2)\n","    cv2.imwrite('LP_conv_1.png', output)\n","\n","    kernel2 = np.ones((3,3),np.float32)/9\n","    output = cv2.filter2D(output,-1,kernel2)\n","    cv2.imwrite('LP_filter_1.png', output)\n","\n","    output=pool2d(output, kernel_size=2, stride=2, padding=0, pool_mode='max')\n","    cv2.imwrite('LP_pool_1.png', output)\n","\n"],"metadata":{"id":"bbTCkebv7CrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","img = cv2.imread('phpDlNSHI.png')\n","\n","kernel = np.ones((5,5),np.float32)/25\n","dst = cv2.filter2D(img,-1,kernel)\n","\n","plt.subplot(121),plt.imshow(img),plt.title('Original')\n","plt.xticks([]), plt.yticks([])\n","plt.subplot(122),plt.imshow(dst),plt.title('Averaging')\n","plt.xticks([]), plt.yticks([])\n","plt.show()"],"metadata":{"id":"eiv_3Ch-6qsQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  image = processImage('son.png')    \n","  image = cv2.cvtColor(src=image, code=cv2.COLOR_BGR2GRAY)\n","  cv2.imwrite('son_bw.png', image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QEI8eGgqi45M","executionInfo":{"status":"ok","timestamp":1642498650421,"user_tz":-180,"elapsed":7,"user":{"displayName":"acil yedek56","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi62S6A3kXIVMwAqQEIpMih0vnTXitcIO-3tzuB=s64","userId":"10231977694557926650"}},"outputId":"88a762ae-e1f4-4993-d820-deb9f0126914"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"TRmPUNBXTJkF"},"source":["import sys\n","\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","import keras \n","from numpy.lib.stride_tricks import as_strided\n","from sklearn.preprocessing import normalize\n","\n","\n","# Grayscale Image\n","def processImage(image):\n","    image = cv2.imread(image)\n","    image = cv2.cvtColor(src=image, code=cv2.COLOR_BGR2GRAY)\n","    return image\n","\n","\n","def convolve2D(image, kernel, padding=0, strides=1):\n","    # Cross Correlation\n","    kernel = np.flipud(np.fliplr(kernel))\n","\n","    # Gather Shapes of Kernel + Image + Padding\n","    xKernShape = kernel.shape[0]\n","    yKernShape = kernel.shape[1]\n","    xImgShape = image.shape[0]\n","    yImgShape = image.shape[0]\n","\n","    # Shape of Output Convolution\n","    xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1)\n","    yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1)\n","    output = np.zeros((xOutput, yOutput))\n","\n","    # Apply Equal Padding to All Sides\n","    if padding != 0:\n","        imagePadded = np.zeros((image.shape[0] + padding*2, image.shape[1] + padding*2))\n","        imagePadded[int(padding):int(-1 * padding), int(padding):int(-1 * padding)] = image\n","    else:\n","        imagePadded = image\n","\n","    # Iterate through image\n","    for y in range(image.shape[1]):\n","        # Exit Convolution\n","        if y > image.shape[1] - yKernShape:\n","            break\n","        # Only Convolve if y has gone down by the specified Strides\n","        if y % strides == 0:\n","            for x in range(image.shape[0]):\n","                # Go to next row once kernel is out of bounds\n","                if x > image.shape[0] - xKernShape:\n","                    break\n","                try:\n","                    # Only Convolve if x has moved by the specified Strides\n","                    if x % strides == 0:\n","                        output[x, y] = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]).sum()\n","                except:\n","                    break\n","\n","    return output\n","\n","\n","def pool2d(A, kernel_size, stride, padding=0, pool_mode='max'):\n","    '''\n","    2D Pooling\n","\n","    Parameters:\n","      A: input 2D array\n","      kernel_size: int, the size of the window over which we take pool\n","      stride: int, the stride of the window\n","      padding: int, implicit zero paddings on both sides of the input\n","      pool_mode: string, 'max' or 'avg'\n","    '''\n","    # Padding\n","    A = np.pad(A, padding, mode='constant')\n","\n","    # Window view of A\n","    output_shape = ((A.shape[0] - kernel_size) // stride + 1,\n","                (A.shape[1] - kernel_size) // stride + 1)\n","\n","    shape_w = (output_shape[0], output_shape[1], kernel_size, kernel_size)\n","    strides_w = (stride*A.strides[0], stride*A.strides[1], A.strides[0], A.strides[1])\n","\n","    A_w = as_strided(A, shape_w, strides_w)\n","\n","    # Return the result of pooling\n","    if pool_mode == 'max':\n","      return A_w.max(axis=(2, 3))\n","    elif pool_mode == 'avg':\n","      return A_w.mean(axis=(2, 3))\n","\n","if __name__ == '__main__':\n","    # Grayscale Image\n","    image = processImage('Picture2.png')\n","\n","    #XDirection Kernel\n","    kernel=np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n","  \n","    # Convolve and Save Output\n","    output = convolve2D(image, kernel, padding=2)\n","    cv2.imwrite('original_conv_1.png', output)\n","\n","    output=pool2d(output, kernel_size=2, stride=2, padding=0, pool_mode='max')\n","    cv2.imwrite('original_pool_1.png', output)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Cfv2oZQ8co9z"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hF3PN6foe9kX"},"source":["import sys\n","import cv2\n","import torch\n","import numpy as np\n","from torch.nn import functional as F\n","import torchvision.transforms as transforms\n","\n","\n","# Grayscale Image\n","def processImage(image):\n","    image = cv2.imread(image)\n","    image = cv2.cvtColor(src=image, code=cv2.COLOR_BGR2GRAY)\n","    return image\n","\n","\n","def convolve2D(image, kernel, padding=0, strides=1):\n","    # Cross Correlation\n","    kernel = np.flipud(np.fliplr(kernel))\n","\n","    # Gather Shapes of Kernel + Image + Padding\n","    xKernShape = kernel.shape[0]\n","    yKernShape = kernel.shape[1]\n","    xImgShape = image.shape[0]\n","    yImgShape = image.shape[0]\n","\n","    # Shape of Output Convolution\n","    xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1)\n","    yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1)\n","    output = np.zeros((xOutput, yOutput))\n","\n","    # Apply Equal Padding to All Sides\n","    if padding != 0:\n","        imagePadded = np.zeros((image.shape[0] + padding*2, image.shape[1] + padding*2))\n","        imagePadded[int(padding):int(-1 * padding), int(padding):int(-1 * padding)] = image\n","    else:\n","        imagePadded = image\n","\n","    # Iterate through image\n","    for y in range(image.shape[1]):\n","        # Exit Convolution\n","        if y > image.shape[1] - yKernShape:\n","            break\n","        # Only Convolve if y has gone down by the specified Strides\n","        if y % strides == 0:\n","            for x in range(image.shape[0]):\n","                # Go to next row once kernel is out of bounds\n","                if x > image.shape[0] - xKernShape:\n","                    break\n","                try:\n","                    # Only Convolve if x has moved by the specified Strides\n","                    if x % strides == 0:\n","                        output[x, y] = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]).sum()\n","                except:\n","                    break\n","\n","    return output\n","def pool2d(A, kernel_size, stride, padding=0, pool_mode='max'):\n","    '''\n","    2D Pooling\n","\n","    Parameters:\n","      A: input 2D array\n","      kernel_size: int, the size of the window over which we take pool\n","      stride: int, the stride of the window\n","      padding: int, implicit zero paddings on both sides of the input\n","      pool_mode: string, 'max' or 'avg'\n","    '''\n","    # Padding\n","    A = np.pad(A, padding, mode='constant')\n","\n","    # Window view of A\n","    output_shape = ((A.shape[0] - kernel_size) // stride + 1,\n","                (A.shape[1] - kernel_size) // stride + 1)\n","\n","    shape_w = (output_shape[0], output_shape[1], kernel_size, kernel_size)\n","    strides_w = (stride*A.strides[0], stride*A.strides[1], A.strides[0], A.strides[1])\n","\n","    A_w = as_strided(A, shape_w, strides_w)\n","\n","    # Return the result of pooling\n","    if pool_mode == 'max':\n","      return A_w.max(axis=(2, 3))\n","    elif pool_mode == 'avg':\n","      return A_w.mean(axis=(2, 3))\n","\n","\n","if __name__ == '__main__':\n","\n","    trans = transforms.ToPILImage()\n","    trans1 = transforms.ToTensor()\n","    # Grayscale Image\n","    image = processImage('Picture2.png')\n","\n","\n","    #XDirection Kernel\n","    kernel=np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n","  \n","    # Convolve and Save Output\n","    \n","    all_shifts = [  \n","              (1, 0, 0, 0), (0, 0, 1, 0),\n","                      (1, 0, 1, 0), (1, 0, 0, 1),\n","                      (0, 1, 0, 1), (0, 1, 1, 0),\n","                      (0, 1, 0, 0), (0, 0, 0, 1),\n","             \n","                    \n","                    ]\n","    outputs = [] \n"," \n","    output = processImage('original_conv_1.png')   \n","    outputs.append(torch.tensor(output))  \n","    for shift in all_shifts[0:]:\n","       i=0\n","       input= trans1(image).unsqueeze(0) \n","       out = F.pad(input , pad=shift, mode='circular')  \n","       shifted_data = out[:, :, :, :]\n","       sonuc= trans(shifted_data.squeeze(0))\n","       img = cv2.cvtColor(cv2.UMat( np.array(sonuc)), cv2.COLOR_BGR2RGB )\n","       #cv2.imwrite ('/content/gdrive/MyDrive/2DConvolved_cs_1+2.png',img)\n","  \n","\n","       output = convolve2D(np.array(sonuc), kernel, padding=2) \n","       #output= relu(output)\n","           \n","       output = output[ 0: 602, 0 : 602]\n","          \n","       outputs.append(torch.tensor(output))\n","\n","    average = torch.mean(torch.stack(outputs), 0)\n","    output=np.asarray(average)\n","  \n","    \n","    cv2.imwrite('CS_conv_1.png', output)\n","    \n","    \n","    output=pool2d(output, kernel_size=2, stride=2, padding=0, pool_mode='max')\n","    cv2.imwrite('CS_pool_1.png', output)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    # import module\n","    from PIL import Image, ImageChops\n","  \n","    # assign images\n","    img1 = Image.open(\"pool_original_X.png\")\n","    img2 = Image.open(\"pool_CS_X.png\")\n","  \n","    # finding difference\n","    diff = ImageChops.difference(img1, img2)\n","    cv2.imwrite('2DConvolved_diff_X.png', np.asarray(diff))\n","\n","    # showing the difference\n","    diff.show()"],"metadata":{"id":"R8yZurF-isAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBZttim_XZRP"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LiD44y6rBdgH"},"source":["import numpy as np \n","import torch\n","import torch.nn.functional as F\n","from google.colab import files\n","from io import BytesIO\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Comment 0: define transformation that you wish to apply on image\n","data_transforms = transforms.Compose([\n","                    transforms.CenterCrop(224),\n","                    transforms.ToTensor()])\n","\n","from google.colab import files\n","from io import BytesIO\n","from PIL import Image\n","import cv2\n","import numpy as np\n","\n","uploaded = files.upload()\n","img = Image.open(BytesIO(uploaded['deneme1.png']))\n","\n","trans = transforms.ToPILImage()\n","trans1 = transforms.ToTensor()\n","\n","\n","model = torch.nn.Conv2d(3, 33, 3, stride=2)\n","original=model(torch.from_numpy(trans1))\n","cv2.imwrite ('/content/gdrive/MyDrive/deneme1_original.png',original)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fcb_GuFBBYAZ"},"source":["\n","print(trans1(img).size())\n","\n","all_shifts = [              \n","              (0, 0, 2,0),                         \n","                      ]\n","for shift in all_shifts[0:]: \n","\n","  input= trans1(img).unsqueeze(0) \n","  out = F.pad(input , pad=shift, mode='circular')\n","  (batch,channel, h, w) = out.size() \n","  shifted_data = out[:, :, :, :]  \n","\n","  sonuc= trans(shifted_data.squeeze(0))\n","  img = cv2.cvtColor(cv2.UMat( np.array(sonuc)), cv2.COLOR_BGR2RGB )\n","  cv2.imwrite ('/content/gdrive/MyDrive/deneme1.png',img)\n","  plt.imshow(trans(shifted_data.squeeze(0)))\n","  plt.show()\n","  \n","  cs=model(torch.from_numpy(img))\n","  cv2.imwrite ('/content/gdrive/MyDrive/deneme1_cs.png',cs)\n","  (batcImg0,channelImg0,hImg0,wImg0)=cs.size()\n","        \n","  for shift in all_shifts[1:]:\n","            padded = F.pad(x, (shift[0], shift[1], shift[2], shift[3]), mode='circular')\n","            (batch, channel, h, w) = padded.size()\n","            cs=model(torch.from_numpy(padded))      \n","            output = output[:, :, 0: hImg0, 0 : wImg0]\n","          \n","            outputs.append(output)\n","\n","  average = torch.mean(torch.stack(outputs), 0)\n","\n","\n","  "],"execution_count":null,"outputs":[]}]}